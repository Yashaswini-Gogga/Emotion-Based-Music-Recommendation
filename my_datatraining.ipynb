{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ad8910-6541-44be-9443-c6a23db29de2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
import os  
import numpy as np 
from tensorflow.keras.utils import to_categorical
from keras.layers import Input, Dense 
from keras.models import Model

# Set the directory path where your .npy files are located
data_directory = 'C:/Users/yasha/OneDrive/Desktop/emotion based music recommendor final/emotion-based-music-main/mine'  # Update with the correct path

is_init = False
size = -1

label = []
dictionary = {}
c = 0

# Debugging: Print files in the specified directory
print("Files in the directory:")
print(os.listdir(data_directory))

for i in os.listdir(data_directory):
    if i.split(".")[-1] == "npy" and not(i.split(".")[0] == "labels"):  
        print(f"Processing file: {i}")  # Debugging: Print file being processed
        if not(is_init):
            is_init = True 
            X = np.load(os.path.join(data_directory, i))
            size = X.shape[0]
            y = np.array([i.split('.')[0]]*size).reshape(-1,1)
        else:
            X = np.concatenate((X, np.load(os.path.join(data_directory, i))))
            y = np.concatenate((y, np.array([i.split('.')[0]]*size).reshape(-1,1)))

        label.append(i.split('.')[0])
        dictionary[i.split('.')[0]] = c  
        c = c+1

# Ensure y is populated
if 'y' not in locals():
    raise ValueError("The 'y' array is not defined. Check the data loading section.")

# Mapping the labels
for i in range(y.shape[0]):
    y[i, 0] = dictionary[y[i, 0]]
y = np.array(y, dtype="int32")

# Apply one-hot encoding to y
y = to_categorical(y)

X_new = X.copy()
y_new = y.copy()
counter = 0 

# Shuffle the data
cnt = np.arange(X.shape[0])
np.random.shuffle(cnt)

for i in cnt: 
    X_new[counter] = X[i]
    y_new[counter] = y[i]
    counter = counter + 1

# Model definition
ip = Input(shape=(X.shape[1],))  # Correct input shape here

m = Dense(512, activation="relu")(ip)
m = Dense(256, activation="relu")(m)

op = Dense(y.shape[1], activation="softmax")(m) 

model = Model(inputs=ip, outputs=op)

# Compile the model
model.compile(optimizer='rmsprop', loss="categorical_crossentropy", metrics=['acc'])

# Train the model with the shuffled data
model.fit(X_new, y_new, epochs=50)

# Save the model and labels
model.save("model.h5")
np.save("labels.npy", np.array(label))
